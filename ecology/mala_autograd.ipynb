{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling libraries:\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np, time, matplotlib.pyplot as plt, math, pandas, numpy.random as npr, multiprocessing as mp, torch, copy\n",
    "from pylab import plot, show, legend\n",
    "from time import time\n",
    "from scipy.stats import *\n",
    "from tqdm import trange\n",
    "from ecology_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "I = 5  # number of locations\n",
    "J = 3  # number of species\n",
    "K = 2   # number of latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = torch.randn(J,K, requires_grad=True)\n",
    "alpha = torch.randn(J,1, requires_grad=True)\n",
    "c = torch.tensor(0., requires_grad=True)\n",
    "phi = torch.tensor(0.5, requires_grad=True)\n",
    "logsigmasq = torch.tensor(0., requires_grad=True)\n",
    "x_0 = torch.randn(I,K, requires_grad=False)\n",
    "\n",
    "theta = [alpha, lmbda, c, phi, logsigmasq]\n",
    "theta_np = [theta[i].detach().numpy() for i in range(5)]\n",
    "Y, X = simulate_data(x_0, T, J, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:15<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "n_particles = 1_000\n",
    "rep = 20\n",
    "alpha_grad = np.zeros((rep,J,1))\n",
    "lmbda_grad = np.zeros((rep,J,K))\n",
    "c_grad = np.zeros(rep)\n",
    "phi_grad = np.zeros(rep)\n",
    "logsigmasq_grad = np.zeros(rep)\n",
    "for r in trange(rep) :\n",
    "    theta = [copy.deepcopy(alpha), copy.deepcopy(lmbda), copy.deepcopy(c), copy.deepcopy(phi), copy.deepcopy(logsigmasq)]\n",
    "    logNC = bootstrap_PF_grad_autodiff(x_0, n_particles, theta, Y)\n",
    "    alpha_grad[r] = theta[0].grad.detach()\n",
    "    lmbda_grad[r] = theta[1].grad.detach()\n",
    "    c_grad[r] = theta[2].grad.detach()\n",
    "    phi_grad[r] = theta[3].grad.detach()\n",
    "    logsigmasq_grad[r] = theta[4].grad.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-212.93578262]\n",
      " [-126.33988342]\n",
      " [-176.87940903]]\n",
      "[[-30.80315576  15.57667055]\n",
      " [ 15.99725367  -5.02096578]\n",
      " [-16.54748445  -1.43537828]]\n",
      "18.684779930114747\n",
      "67.58846230506897\n",
      "44.177459478378296\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(alpha_grad,0))\n",
    "print(np.mean(lmbda_grad,0))\n",
    "print(np.mean(c_grad,0))\n",
    "print(np.mean(phi_grad,0))\n",
    "print(np.mean(logsigmasq_grad,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau = np.asarray([1e-4, 1e-3, 1e-4, 1e-3, 1e-3])/10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/postdoc/dsen/Desktop/codes/DC-BATS/ecology/ecology_functions.py:396: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = power*(ll_proposed-torch.tensor(ll_current)) + (log_prior_proposed-log_prior_current)\n",
      " 63%|██████▎   | 63/100 [00:51<00:31,  1.17it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "assigned grad has data of a different size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e49163a050dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_mcmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtheta_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMCMC_mala\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mcmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/codes/DC-BATS/ecology/ecology_functions.py\u001b[0m in \u001b[0;36mpMCMC_mala\u001b[0;34m(x_0, Y, theta_0, n_particles, n_mcmc, tau, power)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_jump\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;31m# set theta gradient to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0mll_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_PF_grad_autodiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/codes/DC-BATS/ecology/ecology_functions.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mlmbda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mlogsigmasq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: assigned grad has data of a different size"
     ]
    }
   ],
   "source": [
    "n_particles = 1000\n",
    "n_mcmc = 100\n",
    "theta_chain, accept_probs = pMCMC_mala(x_0, Y, theta, n_particles, n_mcmc, tau, power=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(1.2, requires_grad=True)\n",
    "res = a*torch.ones(10)\n",
    "# res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2000, requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.34343281e-09]\n",
      " [1.32862478e-09]\n",
      " [1.41325872e-09]]\n",
      "[[425.32674606 488.72661034]\n",
      " [447.27663419 514.1390499 ]\n",
      " [430.82065309 475.72450216]]\n",
      "6.011454388499261e-10\n",
      "1730.4517527633598\n",
      "121.51384155282521\n"
     ]
    }
   ],
   "source": [
    "print(np.var(alpha_grad,0))\n",
    "print(np.var(lmbda_grad,0))\n",
    "print(np.var(c_grad))\n",
    "print(np.var(phi_grad))\n",
    "print(np.var(logsigmasq_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:02<00:00,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "n_particles = 10_000\n",
    "rep = 100\n",
    "alpha_grad = np.zeros((rep,J,1))\n",
    "lmbda_grad = np.zeros((rep,J,K))\n",
    "c_grad = np.zeros(rep)\n",
    "phi_grad = np.zeros(rep)\n",
    "logsigmasq_grad = np.zeros(rep)\n",
    "for r in trange(rep) :\n",
    "    theta = [copy.deepcopy(alpha), copy.deepcopy(lmbda), copy.deepcopy(c), copy.deepcopy(phi), copy.deepcopy(logsigmasq)]\n",
    "    logNC = bootstrap_PF_grad_autodiff(x_0, n_particles, theta, Y)\n",
    "    alpha_grad[r] = theta[0].grad.detach()\n",
    "    lmbda_grad[r] = theta[1].grad.detach()\n",
    "    c_grad[r] = theta[2].grad.detach()\n",
    "    phi_grad[r] = theta[3].grad.detach()\n",
    "    logsigmasq_grad[r] = theta[4].grad.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.22087668e-08]\n",
      " [2.48453347e-08]\n",
      " [3.16728605e-08]]\n",
      "[[356.61384121 514.57233179]\n",
      " [454.6916215  509.74419351]\n",
      " [354.31965796 459.24901315]]\n",
      "2.4879351258277895e-09\n",
      "2053.3949930821072\n",
      "165.29161700219717\n"
     ]
    }
   ],
   "source": [
    "print(np.var(alpha_grad,0))\n",
    "print(np.var(lmbda_grad,0))\n",
    "print(np.var(c_grad))\n",
    "print(np.var(phi_grad))\n",
    "print(np.var(logsigmasq_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.sum(alpha**2)\n",
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7364],\n",
       "        [-0.3087],\n",
       "        [ 0.3533]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 1e-3\n",
    "alpha + tau*alpha.grad.detach() + np.sqrt(2*tau)*torch.randn(*np.shape(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha.grad = torch.zeros(*np.shape(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
