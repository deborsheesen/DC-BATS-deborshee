{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{Latent:} \\quad X_t & = & A X_{t-1}  + \\nu_t, \n",
    "\\\\\n",
    "\\text{Observed:} \\quad Y_t & = & C X_t + B Z_t + \\omega_t, \\quad Z_t ~ \\text{are covariates}\n",
    "\\\\\n",
    "\\nu_t & \\sim & \\text{N}(0, Q ),\n",
    "\\\\\n",
    "\\omega_t & \\sim & \\text{N}(0, R).\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np, numpy.random as npr, matplotlib.pyplot as plt, copy, multiprocessing as mp, torch, pandas\n",
    "from scipy.stats import *\n",
    "from pylab import plot, show, legend\n",
    "from tqdm import trange\n",
    "from ozone_functions import *\n",
    "from torch.distributions import multivariate_normal\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data.csv\").values\n",
    "data = data[:,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = np.shape(data)[0]\n",
    "Y = torch.FloatTensor(data[:,0:3])\n",
    "Z = torch.FloatTensor(data[:,3::])\n",
    "\n",
    "obs_dim = np.shape(Y)[-1]\n",
    "lat_dim = 1\n",
    "cov_dim = np.shape(Z)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = torch.zeros(lat_dim,lat_dim, requires_grad=True)\n",
    "C = torch.randn(obs_dim,lat_dim, requires_grad=True)\n",
    "log_sigmay2 = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "Q = torch.eye(lat_dim)\n",
    "R = torch.exp(log_sigmay2)*torch.eye(obs_dim)\n",
    "\n",
    "B = torch.randn(obs_dim,cov_dim, requires_grad=True)\n",
    "b = (torch.matmul(B,Z.transpose(0,1))).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu0 = torch.zeros(lat_dim)\n",
    "Sigma0 = torch.eye(lat_dim)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filtering_mean = np.zeros((T,lat_dim))\n",
    "predictive_mean = np.zeros((T,lat_dim))\n",
    "filtering_cov = np.zeros((T,lat_dim,lat_dim))\n",
    "predictive_cov = np.zeros((T,lat_dim,lat_dim))\n",
    "\n",
    "filtering_mean[0] = mu0\n",
    "filtering_cov[0] = Sigma0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in trange(1000) :\n",
    "    for t in range(T) :\n",
    "        predictive_mean[t] = A.dot(filtering_mean[t])\n",
    "        predictive_cov[t] = A.dot(filtering_cov[t]).dot(A.transpose())\n",
    "        K = predictive_cov[t].dot(C.transpose()).dot(np.linalg.inv(C.dot(predictive_cov[t]).dot(C.transpose())+R))\n",
    "        filtering_mean[t] = predictive_mean[t] + K.dot(Y[t]-C.dot(predictive_mean[t]))\n",
    "        filtering_cov[t] = (np.eye(lat_dim)-K.dot(C)).dot(predictive_cov[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, torch.Size([3, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_dim, obs_dim, np.shape(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lpdf(Y, Z, A, C, B, log_sigmay2, mu0, Sigma0) :\n",
    "    T = np.shape(Y)[0]\n",
    "    filtering_mean = torch.clone(mu0.detach())\n",
    "    filtering_cov = torch.clone(Sigma0.detach())\n",
    "    \n",
    "    lat_dim = np.shape(A)[0]\n",
    "    obs_din = np.shape(C)[0]\n",
    "\n",
    "    lpdf = torch.tensor(0.)\n",
    "    Q = torch.eye(lat_dim)\n",
    "    R = torch.exp(log_sigmay2)*torch.eye(obs_dim)\n",
    "\n",
    "    for t in range(T) :\n",
    "        predictive_mean = torch.matmul(A,filtering_mean)\n",
    "        predictive_cov = torch.matmul(A,torch.matmul(filtering_cov,A.transpose(0,1)))\n",
    "\n",
    "        K = torch.matmul(torch.matmul(predictive_cov,C.transpose(0,1)),\\\n",
    "                         (torch.inverse(torch.matmul(torch.matmul(C,predictive_cov),C.transpose(0,1))+R)))\n",
    "        filtering_mean = predictive_mean + torch.matmul(K,(Y[t]- torch.matmul(C,predictive_mean)))\n",
    "        filtering_cov = torch.matmul(torch.eye(lat_dim) - torch.matmul(K,C), predictive_cov) + Q\n",
    "\n",
    "        mean = torch.matmul(C,filtering_mean) + b[t] \n",
    "        cov = torch.matmul(C,torch.matmul(filtering_cov,C.transpose(0,1))) + R\n",
    "\n",
    "        dist = multivariate_normal.MultivariateNormal(loc=mean,covariance_matrix=cov)\n",
    "        lpdf += dist.log_prob(Y[t])\n",
    "    \n",
    "    lpdf.backward(retain_graph=True)\n",
    "    \n",
    "    return lpdf, A.grad, C.grad, B.grad, log_sigmay2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07656693458557129\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "lpdf, A_grad, C_grad, B_grad, log_sigmay2_grad = get_lpdf(Y[:100], Z[:100], A, C, B, log_sigmay2, mu0, Sigma0)\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.]], dtype=float32), tensor([[-219742.5938],\n",
       "         [ 172460.3906],\n",
       "         [  79737.4141]]), tensor([[-243049.7656, -472102.0000],\n",
       "         [ 182992.8750,  377115.3750],\n",
       "         [  85311.6641,  173620.4844]]), tensor(333977.8125))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_grad.numpy(), C_grad, B_grad, log_sigmay2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_MALA(Y, Z, A, C, B, log_sigmay2, mu0, Sigma0, \n",
    "                  n_mcmc, tauA, tauC, tausy, adapt=True, start_adapt=0.2, power=1, kappa=1) :\n",
    "    \n",
    "    npr.seed()\n",
    "    scipy.random.seed()\n",
    "    \n",
    "    log_sigmay2_chain = torch.zeros(n_mcmc+1, requires_grad=False)\n",
    "    log_sigmay2_chain[0] = log_sigmay2\n",
    "    A_chain = torch.zeros((n_mcmc+1, *np.shape(A)), requires_grad=False)\n",
    "    C_chain = torch.zeros((n_mcmc+1, *np.shape(C)), requires_grad=False)\n",
    "    B_chain = torch.zeros((n_mcmc+1, *np.shape(B)), requires_grad=False)\n",
    "    A_chain[0], C_chain[0], B_chain[0] = A, C, B\n",
    "    \n",
    "    accepted = 0\n",
    "    last_accepted = 0\n",
    "    \n",
    "    start = time()\n",
    "    A_current = torch.clone(A.detach())\n",
    "    C_current = torch.clone(C.detach())\n",
    "    B_current = torch.clone(B.detach())\n",
    "    log_sigmay2_current = torch.clone(log_sigmay2.detach()) \n",
    "    \n",
    "    A_current.requires_grad = True\n",
    "    C_current.requires_grad = True\n",
    "    B_current.requires_grad = True\n",
    "    log_sigmay2_current.requires_grad = True\n",
    "    \n",
    "    for n in trange(n_mcmc) :\n",
    "        \n",
    "        ll_current, A_grad, C_grad, B_grad, log_sigmay2_grad \\\n",
    "        = get_lpdf(Y, Z, A_current, C_current, B_current, log_sigmay2_current, mu0, Sigma0)\n",
    "    \n",
    "        log_sigmay2_proposed = torch.tensor((log_sigmay2_current + tausy*log_sigmay2_grad \\\n",
    "                                             + torch.sqrt(2*tausy)*torch.randn(1)).detach().numpy(),\n",
    "                                            requires_grad=True)\n",
    "        A_proposed = torch.tensor((A_current + tauA*A_grad + torch.sqrt(2*tauA)*torch.randn(*np.shape(A))).detach().numpy(), \n",
    "                                  requires_grad=True)\n",
    "        C_proposed = torch.tensor((C_current + tauC*C_grad + torch.sqrt(2*tauC)*torch.randn(*np.shape(C))).detach().numpy(), \n",
    "                                  requires_grad=True)\n",
    "        B_proposed = torch.clone(B)\n",
    "        \n",
    "        if np.abs(A_proposed.detach().numpy()) < 1 :\n",
    "        \n",
    "            ll_proposed, A_grad_proposed, C_grad_proposed, B_grad_proposed, log_sigmay2_grad_proposed \\\n",
    "            = get_lpdf(Y, Z, A_proposed, C_proposed, B_proposed,\n",
    "                       log_sigmay2_proposed, mu0, Sigma0)\n",
    "\n",
    "            log_accept_ratio = power*(ll_proposed - ll_current)\n",
    "            bottom = -power/(4*tauA)*torch.sum(A_proposed-A_current-tauA*A_grad).detach()**2 \\\n",
    "                     -power/(4*tauC)*torch.sum(C_proposed-C_current-tauC*C_grad).detach()**2 \\\n",
    "                     -power/(4*tausy)*torch.sum(log_sigmay2_proposed-log_sigmay2_current-tausy*log_sigmay2_grad).detach()**2\n",
    "            top = -power/(4*tauA)*torch.sum(A_current-A_proposed-tauA*A_grad_proposed).detach()**2 \\\n",
    "                  -power/(4*tauC)*torch.sum(C_current-C_proposed-tauC*C_grad_proposed).detach()**2 \\\n",
    "                  -power/(4*tausy)*torch.sum(log_sigmay2_current-log_sigmay2_proposed-\\\n",
    "                                              tausy*log_sigmay2_grad_proposed).detach()**2\n",
    "\n",
    "            log_accept_ratio = log_accept_ratio + top-bottom\n",
    "        \n",
    "            if np.log(npr.rand()) < log_accept_ratio.detach().numpy() :\n",
    "                log_sigmay2_chain[n+1] = log_sigmay2_proposed.detach()\n",
    "                A_chain[n+1] = A_proposed.detach()\n",
    "                C_chain[n+1] = C_proposed.detach()\n",
    "                B_chain[n+1] = B_proposed.detach()\n",
    "                A_grad = A_grad_proposed.detach()\n",
    "                C_grad = C_grad_proposed.detach()\n",
    "                log_sigmay2_grad = log_sigmay2_grad_proposed.detach()\n",
    "                accepted += 1\n",
    "                last_accepted = n\n",
    "        else :\n",
    "            log_sigmay2_chain[n+1] = log_sigmay2_current.detach()\n",
    "            A_chain[n+1] = A_current.detach()\n",
    "            C_chain[n+1] = C_current.detach()\n",
    "            B_chain[n+1] = B_current.detach()\n",
    "\n",
    "    \n",
    "    print(100*accepted/n_mcmc, \"% acceptance rate\")\n",
    "    return log_sigmay2_chain.detach().numpy(), A_chain.detach().numpy(), C_chain.detach().numpy(), \\\n",
    "            B_chain.detach().numpy(), accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tauCSS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2be46b6e30ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtausy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlog_sigmay2_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_MALA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigmay2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mcmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtauA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtauC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtausy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2fd7771a656b>\u001b[0m in \u001b[0;36madaptive_MALA\u001b[0;34m(Y, Z, A, C, B, log_sigmay2, mu0, Sigma0, n_mcmc, tauA, tauC, tausy, adapt, start_adapt, power, kappa)\u001b[0m\n\u001b[1;32m     34\u001b[0m         A_proposed = torch.tensor((A_current + tauA*A_grad + torch.sqrt(2*tauA)*torch.randn(*np.shape(A))).detach().numpy(), \n\u001b[1;32m     35\u001b[0m                                   requires_grad=True)\n\u001b[0;32m---> 36\u001b[0;31m         C_proposed = torch.tensor((C_current + tauC*C_grad + torch.sqrt(2*tauCSS)*torch.randn(*np.shape(C))).detach().numpy(), \n\u001b[0m\u001b[1;32m     37\u001b[0m                                   requires_grad=True)\n\u001b[1;32m     38\u001b[0m         \u001b[0mB_proposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tauCSS' is not defined"
     ]
    }
   ],
   "source": [
    "n_mcmc = 500\n",
    "tauA = torch.tensor(1e-5)\n",
    "tauC = torch.tensor(1e-5)\n",
    "tausy = torch.tensor(1e-2)\n",
    "\n",
    "log_sigmay2_chain, A_chain, C_chain, B_chain, accepted = \\\n",
    "adaptive_MALA(Y[:100], Z[:100], A, C, B, log_sigmay2, mu0, Sigma0, n_mcmc, tauA, tauC, tausy, adapt=False, power=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y[:100]\n",
    "Z = Z[:100]\n",
    "power = 1\n",
    "tau = torch.tensor(1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_sigmay2_chain = torch.zeros(n_mcmc+1, requires_grad=False)\n",
    "log_sigmay2_chain[0] = log_sigmay2\n",
    "A_chain = torch.zeros((n_mcmc+1, *np.shape(A)), requires_grad=False)\n",
    "C_chain = torch.zeros((n_mcmc+1, *np.shape(C)), requires_grad=False)\n",
    "B_chain = torch.zeros((n_mcmc+1, *np.shape(B)), requires_grad=False)\n",
    "A_chain[0], C_chain[0], B_chain[0] = A, C, B\n",
    "\n",
    "accepted = 0\n",
    "last_accepted = 0\n",
    "\n",
    "start = time()\n",
    "A_current = torch.clone(A.detach())\n",
    "C_current = torch.clone(C.detach())\n",
    "B_current = torch.clone(B.detach())\n",
    "log_sigmay2_current = torch.clone(log_sigmay2.detach()) \n",
    "\n",
    "A_current.requires_grad = True\n",
    "C_current.requires_grad = True\n",
    "B_current.requires_grad = True\n",
    "log_sigmay2_current.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "ll_current, A_grad, C_grad, B_grad, log_sigmay2_grad \\\n",
    "= get_lpdf(Y, Z, A_current, C_current, B_current, log_sigmay2_current, mu0, Sigma0)\n",
    "\n",
    "log_sigmay2_proposed = torch.tensor((log_sigmay2_current + tau*log_sigmay2_grad \\\n",
    "                                     + torch.sqrt(2*tau)*torch.randn(1)).detach().numpy(),\n",
    "                                    requires_grad=True)\n",
    "A_proposed = torch.tensor((A_current + tau*A_grad + torch.sqrt(2*tau)*torch.randn(*np.shape(A))).detach().numpy(), \n",
    "                          requires_grad=True)\n",
    "C_proposed = torch.tensor((C_current + tau*C_grad + torch.sqrt(2*tau)*torch.randn(*np.shape(C))).detach().numpy(), \n",
    "                          requires_grad=True)\n",
    "B_proposed = torch.clone(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(A_proposed.detach().numpy()) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_proposed, A_grad_proposed, C_grad_proposed, B_grad_proposed, log_sigmay2_grad_proposed \\\n",
    "= get_lpdf(Y, Z, A_proposed, C_proposed, B_proposed,\n",
    "           log_sigmay2_proposed, mu0, Sigma0)\n",
    "\n",
    "log_accept_ratio = power*(ll_proposed - ll_current)\n",
    "bottom = -power/(4*tau)*(torch.sum((A_proposed-A_current-tau*A_grad).detach()**2) \\\n",
    "                     + torch.sum((C_proposed-C_current-tau*C_grad).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_proposed-log_sigmay2_current-tau*log_sigmay2_grad).detach()**2))\n",
    "top = -power/(4*tau)*(torch.sum((A_current-A_proposed-tau*A_grad_proposed).detach()**2) \\\n",
    "                     + torch.sum((C_current-C_proposed-tau*C_grad_proposed).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_current-log_sigmay2_proposed-\\\n",
    "                                  tau*log_sigmay2_grad_proposed).detach()**2))\n",
    "\n",
    "log_accept_ratio = log_accept_ratio + top-bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43.8279, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_accept_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_sigmay2_chain[n+1] = log_sigmay2_proposed.detach()\n",
    "A_chain[n+1] = A_proposed.detach()\n",
    "C_chain[n+1] = C_proposed.detach()\n",
    "B_chain[n+1] = B_proposed.detach()\n",
    "A_grad = A_grad_proposed.detach()\n",
    "C_grad = C_grad_proposed.detach()\n",
    "log_sigmay2_grad = log_sigmay2_grad_proposed.detach()\n",
    "accepted += 1\n",
    "last_accepted = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "ll_current, A_grad, C_grad, B_grad, log_sigmay2_grad \\\n",
    "= get_lpdf(Y, Z, A_current, C_current, B_current, log_sigmay2_current, mu0, Sigma0)\n",
    "\n",
    "log_sigmay2_proposed = torch.tensor((log_sigmay2_current + tau*log_sigmay2_grad \\\n",
    "                                     + torch.sqrt(2*tau)*torch.randn(1)).detach().numpy(),\n",
    "                                    requires_grad=True)\n",
    "A_proposed = torch.tensor((A_current + tau*A_grad + torch.sqrt(2*tau)*torch.randn(*np.shape(A))).detach().numpy(), \n",
    "                          requires_grad=True)\n",
    "C_proposed = torch.tensor((C_current + tau*C_grad + torch.sqrt(2*tau)*torch.randn(*np.shape(C))).detach().numpy(), \n",
    "                          requires_grad=True)\n",
    "B_proposed = torch.clone(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(A_proposed.detach().numpy()) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_proposed, A_grad_proposed, C_grad_proposed, B_grad_proposed, log_sigmay2_grad_proposed \\\n",
    "= get_lpdf(Y, Z, A_proposed, C_proposed, B_proposed,\n",
    "           log_sigmay2_proposed, mu0, Sigma0)\n",
    "\n",
    "log_accept_ratio = power*(ll_proposed - ll_current)\n",
    "bottom = -power/(4*tau)*(torch.sum((A_proposed-A_current-tau*A_grad).detach()**2) \\\n",
    "                     + torch.sum((C_proposed-C_current-tau*C_grad).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_proposed-log_sigmay2_current-tau*log_sigmay2_grad).detach()**2))\n",
    "top = -power/(4*tau)*(torch.sum((A_current-A_proposed-tau*A_grad_proposed).detach()**2) \\\n",
    "                     + torch.sum((C_current-C_proposed-tau*C_grad_proposed).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_current-log_sigmay2_proposed-\\\n",
    "                                  tau*log_sigmay2_grad_proposed).detach()**2))\n",
    "\n",
    "log_accept_ratio = log_accept_ratio + top-bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2076.0916, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_accept_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17330.1875, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_proposed - ll_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.7677)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-19410.0469)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5071e-07)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum((A_proposed-A_current-tau*A_grad).detach()**2) \\\n",
    "                     + torch.sum((C_proposed-C_current-tau*C_grad).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_proposed-log_sigmay2_current-tau*log_sigmay2_grad).detach()**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0003)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum((A_current-A_proposed).detach()**2) \\\n",
    "                     + torch.sum((C_current-C_proposed).detach()**2) \\\n",
    "                     + torch.sum((log_sigmay2_current-log_sigmay2_proposed).detach()**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3562e-05]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_current-A_proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2182e-05],\n",
       "        [2.1449e-05],\n",
       "        [3.5214e-05]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C_current-C_proposed).detach()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0167], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(log_sigmay2_current-log_sigmay2_proposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
